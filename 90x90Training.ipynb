{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec46b6f-6802-4f5a-858f-479071187ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 16:33:36.624596: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-26 16:33:36.624646: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-26 16:33:36.626204: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-26 16:33:36.636841: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-26 16:33:37.739247: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d42d8f9-56b8-42a3-a956-9e293a18fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageDataGenerator(rescale = 1/255)\n",
    "validation = ImageDataGenerator(rescale = 1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afd553e5-c2a9-46b0-93ee-890e63b760d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140002 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 16:33:48.449611: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10905 files belonging to 2 classes.\n",
      "Found 39428 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "full_train = tf.keras.preprocessing.image_dataset_from_directory(\"EEdataset1/Dataset/Train\")\n",
    "full_test = tf.keras.preprocessing.image_dataset_from_directory(\"EEdataset1/Dataset/Test\")\n",
    "full_val = tf.keras.preprocessing.image_dataset_from_directory(\"EEdataset1/Dataset/Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b34048-df7d-44e8-bc60-3954f2e9a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = full_train\n",
    "ds_val = full_val\n",
    "ds_test = full_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "402aa8b0-6e73-41b3-a0e8-3825ee28075a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fake', 'Real']\n"
     ]
    }
   ],
   "source": [
    "# define the batch size and print the image labels\n",
    "#import tensorflow_datasets as tfds\n",
    "\n",
    "batch_size = 64 # Dividing the subsets of the data into smaller chunks that our model can be able to understand.\n",
    "\n",
    "dataset_name = ds_train\n",
    "class_names = full_train.class_names\n",
    "print(class_names) #Display the names of the subfolder that are in the main folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc1597cb-9836-44c7-98af-c512c38413fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize your images and standardize your data to make it for a neural network\n",
    "#Standardize your data\n",
    "size = (90,90)\n",
    "ds_train = ds_train.map(lambda image, label: (tf.image.resize(image, size), label))\n",
    "ds_val = ds_val.map(lambda image, label: (tf.image.resize(image, size), label))\n",
    "ds_test = ds_test.map(lambda image, label: (tf.image.resize(image, size), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efc8092f-178d-44ae-b7a4-af3f1e23f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "506615de-b2d0-4cca-8eac-1ae6217a6f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50fa8082-dc26-4310-af25-7d08880f2a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One_hot / categorical encoding\n",
    "def input_preprocess(image, label):\n",
    "  label = tf.one_hot(label, NUM_CLASSES)\n",
    "  return image, label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    input_preprocess, num_parallel_calls = tf.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(input_preprocess)\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.map(input_preprocess)\n",
    "ds_val = ds_val.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bd541f6-9df8-4338-a8f6-db498fd4d61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model('Keras/90x90Epoch.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8588a722-f504-4748-82cf-cecbb5bc8012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " random_flip (RandomFlip)    (None, 90, 90, 3)         0         \n",
      "                                                                 \n",
      " random_flip_1 (RandomFlip)  (None, 90, 90, 3)         0         \n",
      "                                                                 \n",
      " random_rotation (RandomRot  (None, 90, 90, 3)         0         \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " random_zoom (RandomZoom)    (None, 90, 90, 3)         0         \n",
      "                                                                 \n",
      " random_contrast (RandomCon  (None, 90, 90, 3)         0         \n",
      " trast)                                                          \n",
      "                                                                 \n",
      " random_brightness (RandomB  (None, 90, 90, 3)         0         \n",
      " rightness)                                                      \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 90, 90, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 90, 90, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 90, 90, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 90, 90, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 45, 45, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 45, 45, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 45, 45, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 45, 45, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 45, 45, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 22, 22, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 22, 22, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 22, 22, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 22, 22, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 22, 22, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 11, 11, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 11, 11, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 15488)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1982592   \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2272162 (8.67 MB)\n",
      "Trainable params: 2271010 (8.66 MB)\n",
      "Non-trainable params: 1152 (4.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0849e4c-6db3-48cf-ad02-919bf04aabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "es = EarlyStopping(monitor = \"val_accuracy\", min_delta = 0.01, patience = 10, verbose = 1)\n",
    "class CustomModelCheckpoint(Callback):\n",
    "    def __init__(self, filepath, save_freq):\n",
    "        super(CustomModelCheckpoint, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.save_freq = save_freq\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.save_freq == 0:  # Save on specific iterations (1-indexed)\n",
    "            self.model.save(self.filepath.format(epoch=epoch + 1))\n",
    "#Note: Make a new best Keras file everytime you run the code.\n",
    "model_cp = ModelCheckpoint(filepath = 'Keras/90x90Best8.keras', monitor = \"val_accuracy\",\n",
    "                           save_best_only = True,\n",
    "                           save_weights_only = False,\n",
    "                           verbose = 1)\n",
    "# Define your custom checkpoint for specific iterations\n",
    "specific_iteration_cp = CustomModelCheckpoint(filepath='Keras/90x90Epoch.keras',\n",
    "                                              save_freq=1)  \n",
    "import json\n",
    "import os\n",
    "import tensorflow as tf  # Ensure you have TensorFlow imported\n",
    "\n",
    "# Define the custom callback\n",
    "class HistorySaver(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, file_path):\n",
    "        super().__init__()\n",
    "        self.file_path = file_path\n",
    "        self.history = []  # Initialize as a list\n",
    "        self.last_epoch = 0  # Initialize last_epoch\n",
    "        \n",
    "        # Load existing history if the file exists\n",
    "        if os.path.exists(self.file_path):\n",
    "            with open(self.file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                self.history = data.get('history', [])\n",
    "                self.last_epoch = data.get('last_epoch', 0)  # Load last completed epoch\n",
    "                \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Append the current epoch's logs to the history\n",
    "        self.history.append({**logs, 'epoch': epoch + 1})  # Store epoch as 1-indexed\n",
    "\n",
    "        # Save the updated history to the JSON file\n",
    "        with open(self.file_path, 'w') as file:\n",
    "             json.dump({'history': self.history, 'last_epoch': epoch + 1}, file, indent=4)\n",
    "\n",
    "# Usage\n",
    "file_path = '90x90history.json'\n",
    "history_saver = HistorySaver(file_path)\n",
    "# Load the last completed epoch to start from there\n",
    "start_epoch = history_saver.last_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caf648d3-b5f7-4c5b-a8a5-8b2175ccebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "optimizer = optimizers.Adam(epsilon=0.001)\n",
    "model.compile(\n",
    "    optimizer =  optimizer, loss = \"binary_crossentropy\", metrics = [\"accuracy\", tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.Precision(name = 'precision')\n",
    "                                                                      ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d9006d-5646-47df-b638-dd40cb64245e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "4375/4376 [============================>.] - ETA: 0s - loss: 0.0709 - accuracy: 0.9731 - recall: 0.9731 - precision: 0.9731\n",
      "Epoch 1: val_accuracy improved from -inf to 0.97159, saving model to Keras/90x90Best8.keras\n",
      "4376/4376 [==============================] - 1016s 231ms/step - loss: 0.0709 - accuracy: 0.9731 - recall: 0.9731 - precision: 0.9731 - val_loss: 0.0816 - val_accuracy: 0.9716 - val_recall: 0.9716 - val_precision: 0.9716\n",
      "Epoch 2/11\n",
      "2326/4376 [==============>...............] - ETA: 7:36 - loss: 0.0684 - accuracy: 0.9742 - recall: 0.9742 - precision: 0.9742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: val_accuracy improved from 0.97159 to 0.97322, saving model to Keras/90x90Best8.keras\n",
      "4376/4376 [==============================] - 1018s 233ms/step - loss: 0.0760 - accuracy: 0.9711 - recall: 0.9711 - precision: 0.9711 - val_loss: 0.0747 - val_accuracy: 0.9732 - val_recall: 0.9732 - val_precision: 0.9732\n",
      "Epoch 4/11\n",
      "4375/4376 [============================>.] - ETA: 0s - loss: 0.0726 - accuracy: 0.9729 - recall: 0.9729 - precision: 0.9729\n",
      "Epoch 4: val_accuracy did not improve from 0.97322\n",
      "4376/4376 [==============================] - 1016s 232ms/step - loss: 0.0726 - accuracy: 0.9729 - recall: 0.9729 - precision: 0.9729 - val_loss: 0.0871 - val_accuracy: 0.9684 - val_recall: 0.9684 - val_precision: 0.9684\n",
      "Epoch 5/11\n",
      "4375/4376 [============================>.] - ETA: 0s - loss: 0.0691 - accuracy: 0.9739 - recall: 0.9739 - precision: 0.9739\n",
      "Epoch 5: val_accuracy did not improve from 0.97322\n",
      "4376/4376 [==============================] - 1011s 231ms/step - loss: 0.0692 - accuracy: 0.9739 - recall: 0.9739 - precision: 0.9739 - val_loss: 0.0746 - val_accuracy: 0.9723 - val_recall: 0.9723 - val_precision: 0.9723\n",
      "Epoch 6/11\n",
      "4375/4376 [============================>.] - ETA: 0s - loss: 0.0693 - accuracy: 0.9736 - recall: 0.9736 - precision: 0.9736\n",
      "Epoch 6: val_accuracy did not improve from 0.97322\n",
      "4376/4376 [==============================] - 1009s 231ms/step - loss: 0.0693 - accuracy: 0.9736 - recall: 0.9736 - precision: 0.9736 - val_loss: 0.0899 - val_accuracy: 0.9694 - val_recall: 0.9694 - val_precision: 0.9694\n",
      "Epoch 7/11\n",
      "4375/4376 [============================>.] - ETA: 0s - loss: 0.0708 - accuracy: 0.9730 - recall: 0.9730 - precision: 0.9730\n",
      "Epoch 7: val_accuracy did not improve from 0.97322\n",
      "4376/4376 [==============================] - 1011s 231ms/step - loss: 0.0709 - accuracy: 0.9730 - recall: 0.9730 - precision: 0.9730 - val_loss: 0.1020 - val_accuracy: 0.9643 - val_recall: 0.9643 - val_precision: 0.9643\n",
      "Epoch 8/11\n",
      "4375/4376 [============================>.] - ETA: 0s - loss: 0.0715 - accuracy: 0.9727 - recall: 0.9727 - precision: 0.9727\n",
      "Epoch 8: val_accuracy improved from 0.97322 to 0.97332, saving model to Keras/90x90Best8.keras\n",
      "4376/4376 [==============================] - 1009s 231ms/step - loss: 0.0715 - accuracy: 0.9727 - recall: 0.9727 - precision: 0.9727 - val_loss: 0.0746 - val_accuracy: 0.9733 - val_recall: 0.9733 - val_precision: 0.9733\n",
      "Epoch 9/11\n",
      " 780/4376 [====>.........................] - ETA: 13:23 - loss: 0.0711 - accuracy: 0.9733 - recall: 0.9733 - precision: 0.9733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4375/4376 [============================>.] - ETA: 0s - loss: 0.0699 - accuracy: 0.9736 - recall: 0.9736 - precision: 0.9736\n",
      "Epoch 10: val_accuracy did not improve from 0.97332\n",
      "4376/4376 [==============================] - 1010s 231ms/step - loss: 0.0699 - accuracy: 0.9736 - recall: 0.9736 - precision: 0.9736 - val_loss: 0.0825 - val_accuracy: 0.9712 - val_recall: 0.9712 - val_precision: 0.9712\n",
      "Epoch 11/11\n",
      " 989/4376 [=====>........................] - ETA: 12:33 - loss: 0.0666 - accuracy: 0.9745 - recall: 0.9745 - precision: 0.9745"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "epochs = 11\n",
    "hist = model.fit(ds_train, epochs = epochs, validation_data = ds_val, callbacks = [model_cp, specific_iteration_cp, history_saver], batch_size = 64, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f66d61-9560-40df-a857-984bd6780699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your history_saver instance\n",
    "# Extract accuracy and validation accuracy from the history saved in history_saver\n",
    "train_accuracies = [entry['accuracy'] for entry in history_saver.history]\n",
    "val_accuracies = [entry['val_accuracy'] for entry in history_saver.history]\n",
    "\n",
    "# Create a range of epochs based on the length of the accuracies\n",
    "epochs_range = range(1, len(train_accuracies) + 1)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, train_accuracies, label='Training Accuracy', marker='o')\n",
    "plt.plot(epochs_range, val_accuracies, label='Validation Accuracy', marker='o')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(epochs_range)  # Optional: Set x-ticks to be every epoch\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2469fcf-feca-49ad-8dcb-826097398ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your history_saver instance\n",
    "# Extract accuracy and validation accuracy from the history saved in history_saver\n",
    "train_loss = [entry['loss'] for entry in history_saver.history]\n",
    "val_loss = [entry['val_loss'] for entry in history_saver.history]\n",
    "\n",
    "# Create a range of epochs based on the length of the accuracies\n",
    "epochs_range = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, train_loss, label='Training Loss', marker='o')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss', marker='o')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(epochs_range)  # Optional: Set x-ticks to be every epoch\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea003d5-a17b-4d0b-aefc-5edc968fc165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your history_saver instance\n",
    "# Extract accuracy and validation accuracy from the history saved in history_saver\n",
    "train_precision = [entry['precision'] for entry in history_saver.history]\n",
    "val_precision = [entry['val_precision'] for entry in history_saver.history]\n",
    "\n",
    "# Create a range of epochs based on the length of the accuracies\n",
    "epochs_range = range(1, len(train_precision) + 1)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, train_precision, label='Training Precison', marker='o')\n",
    "plt.plot(epochs_range, val_precision, label='Validation Precison', marker='o')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.xticks(epochs_range)  # Optional: Set x-ticks to be every epoch\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84fdf98-34ea-4b75-ad1c-c6ba7757bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your history_saver instance\n",
    "# Extract accuracy and validation accuracy from the history saved in history_saver\n",
    "train_recall = [entry['recall'] for entry in history_saver.history]\n",
    "val_recall = [entry['val_recall'] for entry in history_saver.history]\n",
    "\n",
    "# Create a range of epochs based on the length of the accuracies\n",
    "epochs_range = range(1, len(train_recall) + 1)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, train_recall, label='Training Recall', marker='o')\n",
    "plt.plot(epochs_range, val_accuracies, label='Validation Recall', marker='o')\n",
    "plt.title('Training and Validation Recall')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.xticks(epochs_range)  # Optional: Set x-ticks to be every epoch\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

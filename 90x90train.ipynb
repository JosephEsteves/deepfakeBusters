{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe0ebc7-84fa-4f2d-9db8-304d889c3b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 11:08:43.940526: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-23 11:08:43.940596: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-23 11:08:43.942015: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-23 11:08:43.952483: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-23 11:08:45.108254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b537df57-8ff1-4d5c-805f-591ebd7d7dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageDataGenerator(rescale = 1/255)\n",
    "validation = ImageDataGenerator(rescale = 1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7db9ac34-652c-4b7f-94f8-0ed8133f85f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140002 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 11:08:55.555709: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10905 files belonging to 2 classes.\n",
      "Found 39428 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "full_train = tf.keras.preprocessing.image_dataset_from_directory(\"EEdataset1/Dataset/Train\")\n",
    "full_test = tf.keras.preprocessing.image_dataset_from_directory(\"EEdataset1/Dataset/Test\")\n",
    "full_val = tf.keras.preprocessing.image_dataset_from_directory(\"EEdataset1/Dataset/Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a0abe9d-02bc-493d-9e30-e89621c0bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = full_train\n",
    "ds_val = full_val\n",
    "ds_test = full_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed5302a4-9308-4af7-b2c1-36877cfc6f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fake', 'Real']\n"
     ]
    }
   ],
   "source": [
    "# define the batch size and print the image labels\n",
    "#import tensorflow_datasets as tfds\n",
    "\n",
    "batch_size = 64 # Dividing the subsets of the data into smaller chunks that our model can be able to understand.\n",
    "\n",
    "dataset_name = ds_train\n",
    "class_names = full_train.class_names\n",
    "print(class_names) #Display the names of the subfolder that are in the main folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "607232c5-569d-430e-ac51-a71178d777e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize your images and standardize your data to make it for a neural network\n",
    "#Standardize your data\n",
    "size = (90,90)\n",
    "ds_train = ds_train.map(lambda image, label: (tf.image.resize(image, size), label))\n",
    "ds_val = ds_val.map(lambda image, label: (tf.image.resize(image, size), label))\n",
    "ds_test = ds_test.map(lambda image, label: (tf.image.resize(image, size), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b41bc8-c929-45d5-ae32-9ca2990236fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0adfc13-2ffb-40fc-aaae-64d7f10c384c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "847526f3-dfa9-45c7-81a4-d8038b052779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One_hot / categorical encoding\n",
    "def input_preprocess(image, label):\n",
    "  label = tf.one_hot(label, NUM_CLASSES)\n",
    "  return image, label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    input_preprocess, num_parallel_calls = tf.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(input_preprocess)\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.map(input_preprocess)\n",
    "ds_val = ds_val.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78fd7883-df5c-48d8-8afa-2e9d011cb981",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=[90,90,3]), #1\n",
    "    tf.keras.layers.RandomFlip(mode='horizontal'),         #2\n",
    "    tf.keras.layers.RandomFlip(mode='vertical'),           #3 \n",
    "    tf.keras.layers.RandomRotation(factor=0.05),           #4\n",
    "    tf.keras.layers.RandomZoom(height_factor=0.05),        #5\n",
    "    tf.keras.layers.RandomContrast(factor = 0.1),          #6\n",
    "    tf.keras.layers.RandomBrightness(factor = 0.2),        #7 \n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu',  kernel_initializer='he_uniform', padding='same'), #8\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu',  kernel_initializer='he_uniform', padding='same'), #9\n",
    "    tf.keras.layers.BatchNormalization(),          #10\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),            #11 \n",
    "    tf.keras.layers.Dropout(0.2),                    #12 \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu',  kernel_initializer='he_uniform', padding='same'), #13\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu',  kernel_initializer='he_uniform', padding='same'), #14\n",
    "    tf.keras.layers.BatchNormalization(), #15\n",
    "    tf.keras.layers.MaxPooling2D((2,2)), #16\n",
    "    tf.keras.layers.Dropout(0.3), #17\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation = 'relu',  kernel_initializer='he_uniform', padding='same'), #18\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation = 'relu',  kernel_initializer='he_uniform', padding='same'), #19\n",
    "    tf.keras.layers.BatchNormalization(), #20\n",
    "    tf.keras.layers.MaxPooling2D((2,2)), #21\n",
    "    tf.keras.layers.Dropout(0.4), #21\n",
    "    tf.keras.layers.Flatten(), #22\n",
    "    tf.keras.layers.Dense(128, activation = 'relu',  kernel_initializer='he_uniform'), #23\n",
    "    tf.keras.layers.BatchNormalization(), #24\n",
    "    tf.keras.layers.Dropout(0.5), #25\n",
    "    tf.keras.layers.Dense(2, activation = 'softmax')#26\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "393e96ec-bfe4-43fb-8135-7f975723b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "optimizer = optimizers.Adam(epsilon=0.001)\n",
    "model.compile(\n",
    "    optimizer = optimizer, loss = \"binary_crossentropy\", metrics = [\"accuracy\", tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.Precision(name = 'precision')\n",
    "                                                                      ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d23bf673-041c-4ea6-8757-e1407ffd9b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " random_flip (RandomFlip)    (None, 90, 90, 3)         0         \n",
      "                                                                 \n",
      " random_flip_1 (RandomFlip)  (None, 90, 90, 3)         0         \n",
      "                                                                 \n",
      " random_rotation (RandomRot  (None, 90, 90, 3)         0         \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " random_zoom (RandomZoom)    (None, 90, 90, 3)         0         \n",
      "                                                                 \n",
      " random_contrast (RandomCon  (None, 90, 90, 3)         0         \n",
      " trast)                                                          \n",
      "                                                                 \n",
      " random_brightness (RandomB  (None, 90, 90, 3)         0         \n",
      " rightness)                                                      \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 90, 90, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 90, 90, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 90, 90, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 90, 90, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 45, 45, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 45, 45, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 45, 45, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 45, 45, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 45, 45, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 22, 22, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 22, 22, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 22, 22, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 22, 22, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 22, 22, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 11, 11, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 11, 11, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 15488)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1982592   \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2272162 (8.67 MB)\n",
      "Trainable params: 2271010 (8.66 MB)\n",
      "Non-trainable params: 1152 (4.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38cb321a-4c5d-4d4d-9c2d-150e163dfcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "es = EarlyStopping(monitor = \"val_accuracy\", min_delta = 0.01, patience = 10, verbose = 1)\n",
    "class CustomModelCheckpoint(Callback):\n",
    "    def __init__(self, filepath, save_freq):\n",
    "        super(CustomModelCheckpoint, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.save_freq = save_freq\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.save_freq == 0:  # Save on specific iterations (1-indexed)\n",
    "            self.model.save(self.filepath.format(epoch=epoch + 1))\n",
    "\n",
    "model_cp = ModelCheckpoint(filepath = 'Keras/90x90Best.keras', monitor = \"val_accuracy\",\n",
    "                           save_best_only = True,\n",
    "                           save_weights_only = False,\n",
    "                           verbose = 1)\n",
    "# Define your custom checkpoint for specific iterations\n",
    "specific_iteration_cp = CustomModelCheckpoint(filepath='Keras/90x90Epoch.keras',\n",
    "                                              save_freq=1)  \n",
    "import json\n",
    "import os\n",
    "import tensorflow as tf  # Ensure you have TensorFlow imported\n",
    "\n",
    "# Define the custom callback\n",
    "class HistorySaver(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, file_path):\n",
    "        super().__init__()\n",
    "        self.file_path = file_path\n",
    "        self.history = []  # Initialize as a list\n",
    "        self.last_epoch = 0  # Initialize last_epoch\n",
    "        \n",
    "        # Load existing history if the file exists\n",
    "        if os.path.exists(self.file_path):\n",
    "            with open(self.file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                self.history = data.get('history', [])\n",
    "                self.last_epoch = data.get('last_epoch', 0)  # Load last completed epoch\n",
    "                \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Append the current epoch's logs to the history\n",
    "        self.history.append({**logs, 'epoch': epoch + 1})  # Store epoch as 1-indexed\n",
    "\n",
    "        # Save the updated history to the JSON file\n",
    "        with open(self.file_path, 'w') as file:\n",
    "             json.dump({'history': self.history, 'last_epoch': epoch + 1}, file, indent=4)\n",
    "\n",
    "# Usage\n",
    "file_path = '90x90history.json'\n",
    "history_saver = HistorySaver(file_path)\n",
    "# Load the last completed epoch to start from there\n",
    "start_epoch = history_saver.last_epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d5ce9-c6a0-459f-966f-4019546a3087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4375/4376 [============================>.] - ETA: 0s - loss: 0.4051 - accuracy: 0.8144 - recall: 0.8144 - precision: 0.8144\n",
      "Epoch 1: val_accuracy improved from -inf to 0.83410, saving model to Keras/90x90Best.keras\n",
      "4376/4376 [==============================] - 997s 227ms/step - loss: 0.4051 - accuracy: 0.8144 - recall: 0.8144 - precision: 0.8144 - val_loss: 0.4261 - val_accuracy: 0.8341 - val_recall: 0.8341 - val_precision: 0.8341\n",
      "Epoch 2/100\n",
      "4375/4376 [============================>.] - ETA: 0s - loss: 0.2357 - accuracy: 0.9024 - recall: 0.9024 - precision: 0.9024\n",
      "Epoch 2: val_accuracy improved from 0.83410 to 0.90433, saving model to Keras/90x90Best.keras\n",
      "4376/4376 [==============================] - 999s 228ms/step - loss: 0.2357 - accuracy: 0.9024 - recall: 0.9024 - precision: 0.9024 - val_loss: 0.2369 - val_accuracy: 0.9043 - val_recall: 0.9043 - val_precision: 0.9043\n",
      "Epoch 3/100\n",
      "4375/4376 [============================>.] - ETA: 0s - loss: 0.1879 - accuracy: 0.9249 - recall: 0.9249 - precision: 0.9249\n",
      "Epoch 3: val_accuracy improved from 0.90433 to 0.92328, saving model to Keras/90x90Best.keras\n",
      "4376/4376 [==============================] - 1003s 229ms/step - loss: 0.1879 - accuracy: 0.9249 - recall: 0.9249 - precision: 0.9249 - val_loss: 0.1931 - val_accuracy: 0.9233 - val_recall: 0.9233 - val_precision: 0.9233\n",
      "Epoch 4/100\n",
      "4375/4376 [============================>.] - ETA: 0s - loss: 0.1695 - accuracy: 0.9328 - recall: 0.9328 - precision: 0.9328\n",
      "Epoch 4: val_accuracy did not improve from 0.92328\n",
      "4376/4376 [==============================] - 1000s 228ms/step - loss: 0.1695 - accuracy: 0.9328 - recall: 0.9328 - precision: 0.9328 - val_loss: 0.2343 - val_accuracy: 0.9106 - val_recall: 0.9106 - val_precision: 0.9106\n",
      "Epoch 5/100\n",
      "4375/4376 [============================>.] - ETA: 0s - loss: 0.1546 - accuracy: 0.9394 - recall: 0.9394 - precision: 0.9394\n",
      "Epoch 5: val_accuracy improved from 0.92328 to 0.92883, saving model to Keras/90x90Best.keras\n",
      "4376/4376 [==============================] - 997s 228ms/step - loss: 0.1546 - accuracy: 0.9394 - recall: 0.9394 - precision: 0.9394 - val_loss: 0.1783 - val_accuracy: 0.9288 - val_recall: 0.9288 - val_precision: 0.9288\n",
      "Epoch 6/100\n",
      "4375/4376 [============================>.] - ETA: 0s - loss: 0.1450 - accuracy: 0.9434 - recall: 0.9434 - precision: 0.9434\n",
      "Epoch 6: val_accuracy improved from 0.92883 to 0.93865, saving model to Keras/90x90Best.keras\n",
      "4376/4376 [==============================] - 1000s 229ms/step - loss: 0.1451 - accuracy: 0.9434 - recall: 0.9434 - precision: 0.9434 - val_loss: 0.1703 - val_accuracy: 0.9386 - val_recall: 0.9386 - val_precision: 0.9386\n",
      "Epoch 7/100\n",
      "4375/4376 [============================>.] - ETA: 0s - loss: 0.1383 - accuracy: 0.9464 - recall: 0.9464 - precision: 0.9464\n",
      "Epoch 7: val_accuracy improved from 0.93865 to 0.94623, saving model to Keras/90x90Best.keras\n",
      "4376/4376 [==============================] - 993s 227ms/step - loss: 0.1383 - accuracy: 0.9464 - recall: 0.9464 - precision: 0.9464 - val_loss: 0.1510 - val_accuracy: 0.9462 - val_recall: 0.9462 - val_precision: 0.9462\n",
      "Epoch 8/100\n",
      "1454/4376 [========>.....................] - ETA: 10:40 - loss: 0.1331 - accuracy: 0.9493 - recall: 0.9493 - precision: 0.9493"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "epochs = 100\n",
    "hist = model.fit(ds_train, epochs = epochs, validation_data = ds_val, callbacks = [model_cp, specific_iteration_cp, history_saver], batch_size = 64, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2813d843-225e-4ae9-9c0c-fc22a73897eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ds_test\n",
    "loss, accuracy, precision, recall = model.evaluate(test)\n",
    "print('Test accuracy :', accuracy)\n",
    "print('recall :', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abee529-cf33-4765-8db0-db60dcda8954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your history_saver instance\n",
    "# Extract accuracy and validation accuracy from the history saved in history_saver\n",
    "train_accuracies = [entry['accuracy'] for entry in history_saver.history]\n",
    "val_accuracies = [entry['val_accuracy'] for entry in history_saver.history]\n",
    "\n",
    "# Create a range of epochs based on the length of the accuracies\n",
    "epochs_range = range(1, len(train_accuracies) + 1)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, train_accuracies, label='Training Accuracy', marker='o')\n",
    "plt.plot(epochs_range, val_accuracies, label='Validation Accuracy', marker='o')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(epochs_range)  # Optional: Set x-ticks to be every epoch\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2bf46e-bcb6-4555-b3dd-299c56b05933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your history_saver instance\n",
    "# Extract accuracy and validation accuracy from the history saved in history_saver\n",
    "train_loss = [entry['loss'] for entry in history_saver.history]\n",
    "val_loss = [entry['val_loss'] for entry in history_saver.history]\n",
    "\n",
    "# Create a range of epochs based on the length of the accuracies\n",
    "epochs_range = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, train_loss, label='Training Loss', marker='o')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss', marker='o')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(epochs_range)  # Optional: Set x-ticks to be every epoch\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd97378a-0135-48a7-8d35-53da7ed4e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your history_saver instance\n",
    "# Extract accuracy and validation accuracy from the history saved in history_saver\n",
    "train_precision = [entry['precision'] for entry in history_saver.history]\n",
    "val_precision = [entry['val_precision'] for entry in history_saver.history]\n",
    "\n",
    "# Create a range of epochs based on the length of the accuracies\n",
    "epochs_range = range(1, len(train_precision) + 1)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, train_precision, label='Training Precison', marker='o')\n",
    "plt.plot(epochs_range, val_precision, label='Validation Precison', marker='o')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision')\n",
    "plt.xticks(epochs_range)  # Optional: Set x-ticks to be every epoch\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d41644-98ff-41ac-9139-022e00450558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your history_saver instance\n",
    "# Extract accuracy and validation accuracy from the history saved in history_saver\n",
    "train_recall = [entry['recall'] for entry in history_saver.history]\n",
    "val_recall = [entry['val_recall'] for entry in history_saver.history]\n",
    "\n",
    "# Create a range of epochs based on the length of the accuracies\n",
    "epochs_range = range(1, len(train_recall) + 1)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, train_recall, label='Training Recall', marker='o')\n",
    "plt.plot(epochs_range, val_accuracies, label='Validation Recall', marker='o')\n",
    "plt.title('Training and Validation Recall')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.xticks(epochs_range)  # Optional: Set x-ticks to be every epoch\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
